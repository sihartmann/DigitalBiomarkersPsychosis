# PIPELINE TO ANALYZE DIGITAL BIOMARKERS

## DESCRIPTION



## INSTALLATION
- Download latest release and extract.

## REQUIREMENTS
- OpenFace (tested with v2.2.0): Download [here](https://github.com/TadasBaltrusaitis/OpenFace/releases/tag/OpenFace_2.2.0) 
- Whisper (tested with r136): Download the standalone version [here](https://github.com/Purfview/whisper-standalone-win/releases/tag/Whisper-OpenAI)
- ffmpeg (tested with version 2024-03-11-git-3d1860ec8d-full_build-www.gyan.dev): Download [here](https://www.gyan.dev/ffmpeg/builds/)

## SET-UP
- Place all required executables/folders into the DigBio folder. Place a copy of the ffmpeg executable into the folder of the whisper installation that contains the file 'whisper.exe'.
- Create a folder for every participant. The name of this folder will be the participant's ID. Each folder must contain the following files, downloaded from HIPAA zoom.
    - [date and time of the interview]_Recording_separate1.mp4
    - [date and time of the interview]_Recording_separate1.mp4
    - [date and time of the interview]_Recording_gvo_1280x720.mp4
- Do not rename these files. If you don't have either video or audio from the recording, you can still run the pipeline, however the output will be reduced.
- If your recordings are not from HIPAA zoom, you will need to rename the files to match the above format.
- Place all of your participants folders into a folder called e.g. 'my_interviews'.

## USAGE
```bash
.\digital_biomarkers.exe --interviews <path to my_interviews> [options]
```
## OUTPUT
- **logs**: Contains logs generated by ffmpeg, whisper and OpenFace (depends on what mode the pipeline is run in). If you encounter any errors, check these first.
- **[participant name]_aligned**: Generated by OpenFace. Contains every frame from the video recording. This folder is quite large, depending on the video length.
- **[participant name].mp4**: The video after OpenFace has processed it, showing gaze and posture.
- **[participant name].csv**: Generated by OpenFace. Contains data on gaze, posture an action units for every frame.
- **[participant name].hog**: Generated by OpenFace.
- **[participant name]_openface_out.csv**: OpenFace summary file. Contains rate of binary action unit activation and also rate for no speech vs. speech.
- **[participant name]_of_details.txt**: Generated by OpenFace. General information on configuration and parameters.
- **[participant name]_nltk_results.txt**: Detailed information on tokenisation, part of speech and dependency tagging. 
- **[participant name]_nltk_results.csv**: Summary file on semantic analysis step. Contains sentiment scores, POS and dependency tagging counts, average similarity score between neighbours and interviewer/participant speech ratio
- **[participant name]_sim_scores.csv**: Generated during semantic analysis. Full matrix showing similarity between each sentence.
- **[participant name]_opensmile.csv**: Generated by Opensmile. Contains information on various acoustic markers per millisecond.
- **[participant name]_summary_opensmile**: Summary of Opensmile results. Shows average of every data point.
- **[participant name]_transcript.txt**: Transcript generated by Whisper for the participant.
- **[participant name]_interviewer_transcript.txt**: Transcript generated by Whisper for the interviewer.
- **[participant name]_video.txt**: Video cropped to only show one person.
- **[participant name]_silences.txt**: Generated by ffmpeg. Contains data on speech and not speech in the participant audio.
- **[participant name]_summary.csv**: Summary file per participant of all pipeline steps.
- **all_summary.csv**: Summary file for all participants. This folder is in the 'interviews' folder.

## OPTIONS:
`--interviews` [path to participant folder] This is the only required argument. Make sure you use the full path.\
`--mode [audio,video,all]` Run only part of the pipeline. See description for more details on what will be run in these modes. The default is all, i.e. the complete pipeline.\
`--verbosity [1,2,3,4]` Change amount of detail in logging output. Recommended (and default mode) is 3. Use 4 if you need to debug something, and 1 or 2 if you want very limited output.\
`--overwrite` Use this if you want to start the entire pipeline again. This will delete all files other than the recordings, so use with caution.\
`--no_cut` Will skip the video cutting step. This option should be used if your video either only shows one person or the format is not 1280x720. You may need to manually trim your videos to only show one person.\
`--whisper_model [tiny,small,base,medium,large]` Change the model that whisper uses for transcription. Default is base.

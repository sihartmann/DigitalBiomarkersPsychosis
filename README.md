# DIGITAL BIOMARKER PIPELINE

## DESCRIPTION
This pipeline can be used to extract data from mental health interviews using HIPAA zoom recordings. It produces data about acoustic features such as pitch and volume. Semantic features are extracted from the generated audio transcript using POS tagging, dependency tagging, similarity scoring and sentiment scoring. Visual features such as gaze, head posititon and [action units](https://www.cs.cmu.edu/~face/facs.htm) are extracted also, and a summary file is generated per participant showing all relevant data. To enable easier comparisons between participants, a summary file for all participants is also generated.
## STEPS
The pipeline includes running [openSMILE](https://audeering.github.io/opensmile/) for audio feature extraction and [Whisper](https://openai.com/index/whisper) for transcription. Semantic analysis is performed on participant audio using [The Natural Language Toolkit](https://www.nltk.org/) and [spaCy](https://spacy.io/). Lastly, [OpenFace](https://cmusatyalab.github.io/openface/) is used to perform video analysis.


## INSTALLATION
- Download latest release ([here](https://github.com/sihartmann/DigitalBiomarkersPsychosis/releases/tag/v1.0)) and extract.

## REQUIREMENTS
- OpenFace (tested with v2.2.0): Download [here](https://github.com/TadasBaltrusaitis/OpenFace/releases/tag/OpenFace_2.2.0)
- Whisper (tested with r136): Download the standalone version [here](https://github.com/Purfview/whisper-standalone-win/releases/tag/Whisper-OpenAI)
- ffmpeg (tested with version 2024-03-11-git-3d1860ec8d-full_build-www.gyan.dev): Download [here](https://www.gyan.dev/ffmpeg/builds/)

## SET-UP
- Place all required executables/folders into the DigBio folder. Place a copy of the ffmpeg executable into the folder of the whisper installation that contains the file 'whisper.exe'.
- Create a folder for every participant. The name of this folder will be the participant's ID. Each folder must contain the following files, downloaded from HIPAA zoom.
    - [date and time of the interview]_Recording_separate1 (mp4 or m4a format accepted)
    - [date and time of the interview]_Recording_separate1 (mp4 or m4a format accepted)
    - [date and time of the interview]_Recording_gvo_1280x720.mp4
- Do not rename these files. If you don't have either video or audio from the recording, you can still run the pipeline, however the output will be reduced.
- If your recordings are not from HIPAA zoom, you will need to rename the files to match the above format.
- Place all of your participants folders into a folder called e.g. 'my_interviews'.

## USAGE
```bash
.\digital_biomarkers.exe
```
Will open popup interface.
Select path to interviews folder and specify all other parameters with the dropdown menu.
- Mode: Run only audio, video or both
- Verbosity: 4 for more detail, 1 and 2 for minimal detail.
- Overwrite old results: Start pipeline from scratch. Will delete all previously generated files, so use with caution.
- Skip video cropping: Check if not using HIPAA zoom. You may need to crop videos manually to only show one person.
- Whisper model: Select different sized models for transcription.
The popup window will close once the pipeline has finished.
## OUTPUT
- **logs**: Contains logs generated by ffmpeg, whisper and OpenFace (depends on what mode the pipeline is run in). If you encounter any errors, check these first.
- **[participant name]_aligned**: Generated by OpenFace. Contains every frame from the video recording. This folder is quite large, depending on the video length.
- **[participant name].mp4**: The video after OpenFace has processed it, showing gaze and posture.
- **[participant name].csv**: Generated by OpenFace. Contains data on gaze, posture an action units for every frame.
- **[participant name].hog**: Generated by OpenFace.
- **[participant name]_openface_out.csv**: OpenFace summary file. Contains rate of binary action unit activation and also rate for no speech vs. speech.
- **[participant name]_of_details.txt**: Generated by OpenFace. General information on configuration and parameters.
- **[participant name]_nltk_results.txt**: Detailed information on tokenisation, part of speech and dependency tagging.
- **[participant name]_nltk_results.csv**: Summary file on semantic analysis step. Contains sentiment scores, POS and dependency tagging counts, average similarity score between neighbours and interviewer/participant speech ratio
- **[participant name]_sim_scores.csv**: Generated during semantic analysis. Full matrix showing similarity between each sentence.
- **[participant name]_opensmile.csv**: Generated by Opensmile. Contains information on various acoustic markers per millisecond.
- **[participant name]_summary_opensmile**: Summary of Opensmile results. Shows average of every data point.
- **[participant name]_transcript.txt**: Transcript generated by Whisper for the participant.
- **[participant name]_interviewer_transcript.txt**: Transcript generated by Whisper for the interviewer.
- **[participant name]_video.txt**: Video cropped to only show one person.
- **[participant name]_silences.txt**: Generated by ffmpeg. Contains data on speech and not speech in the participant audio.
- **[participant name]_summary.csv**: Summary file per participant of all pipeline steps.
- **all_summary.csv**: Summary file for all participants. This folder is in the 'interviews' folder.
